{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96S0rGkNIetQ",
        "outputId": "6c340f5b-5a0e-4217-c749-90e839a3b385"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-community in c:\\users\\amir\\anaconda4\\lib\\site-packages (0.3.29)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from langchain-community) (0.3.76)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from langchain-community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from langchain-community) (2.0.30)\n",
            "Requirement already satisfied: requests<3,>=2.32.5 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from langchain-community) (3.9.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from langchain-community) (0.4.27)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (23.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-community) (2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.20.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.21.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from requests<3,>=2.32.5->langchain-community) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from requests<3,>=2.32.5->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from requests<3,>=2.32.5->langchain-community) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from requests<3,>=2.32.5->langchain-community) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.24.0)\n",
            "Requirement already satisfied: anyio in c:\\users\\amir\\anaconda4\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\amir\\anaconda4\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.6)\n",
            "Requirement already satisfied: sniffio in c:\\users\\amir\\anaconda4\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\amir\\anaconda4\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.14.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install -U langchain-community langchain-huggingface chromadb sentence-transformers transformers accelerate protobuf==4.25.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip uninstall -y transformers\n",
        "!pip uninstall -y transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install transformers==4.41.2\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install accelerate safetensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "MwxDJ0POtrzc"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import DirectoryLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "F3O2g27Go2_o"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "432b0d3f"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC_EiedtpIbx",
        "outputId": "25b0c3c3-3610-4618-c578-015ae43311d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 83 chunks\n"
          ]
        }
      ],
      "source": [
        "# =====================\n",
        "# 1. Load and split data\n",
        "# =====================\n",
        "data_path = r\"C:\\Centraly_Project\\Data\\info.md\"\n",
        "\n",
        "loader = TextLoader(data_path, encoding=\"utf-8\")\n",
        "documents = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=100,\n",
        "    length_function=len,\n",
        "    add_start_index=True\n",
        ")\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "print(f\"Loaded {len(chunks)} chunks\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iI_DWWTEpPEt",
        "outputId": "8ffb9a6f-e593-48f6-e3b7-a01fa7ebed2d"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Failed to import transformers.models.chameleon.configuration_chameleon because of the following error (look up to see its traceback):\nNo module named 'transformers.models.chameleon.configuration_chameleon'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\amir\\anaconda4\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1778\u001b[0m, in \u001b[0;36m_get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
            "File \u001b[1;32mc:\\Users\\amir\\anaconda4\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1324\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers.models.chameleon.configuration_chameleon'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[30], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# =====================\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 2. Create embeddings + ChromaDB\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# =====================\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m HuggingFaceEmbeddings(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence-transformers/all-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m Chroma\u001b[38;5;241m.\u001b[39mfrom_documents(chunks, embeddings, persist_directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./chroma_db\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Data stored in Chroma\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\amir\\anaconda4\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:226\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     emit_warning()\n\u001b[1;32m--> 226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\amir\\anaconda4\\Lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:92\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import sentence_transformers python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     90\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m sentence_transformers\u001b[38;5;241m.\u001b[39mSentenceTransformer(\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name, cache_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_folder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs\n\u001b[0;32m     94\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\amir\\anaconda4\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:327\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[1;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[0m\n\u001b[0;32m    309\u001b[0m has_modules \u001b[38;5;241m=\u001b[39m is_sentence_transformer_model(\n\u001b[0;32m    310\u001b[0m     model_name_or_path,\n\u001b[0;32m    311\u001b[0m     token,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    314\u001b[0m     local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    315\u001b[0m )\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    317\u001b[0m     has_modules\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_model_type(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    326\u001b[0m ):\n\u001b[1;32m--> 327\u001b[0m     modules, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_sbert_model(\n\u001b[0;32m    328\u001b[0m         model_name_or_path,\n\u001b[0;32m    329\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m    330\u001b[0m         cache_folder\u001b[38;5;241m=\u001b[39mcache_folder,\n\u001b[0;32m    331\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    332\u001b[0m         trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[0;32m    333\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    334\u001b[0m         model_kwargs\u001b[38;5;241m=\u001b[39mmodel_kwargs,\n\u001b[0;32m    335\u001b[0m         tokenizer_kwargs\u001b[38;5;241m=\u001b[39mtokenizer_kwargs,\n\u001b[0;32m    336\u001b[0m         config_kwargs\u001b[38;5;241m=\u001b[39mconfig_kwargs,\n\u001b[0;32m    337\u001b[0m     )\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    339\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_auto_model(\n\u001b[0;32m    340\u001b[0m         model_name_or_path,\n\u001b[0;32m    341\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    349\u001b[0m         has_modules\u001b[38;5;241m=\u001b[39mhas_modules,\n\u001b[0;32m    350\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\amir\\anaconda4\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:2253\u001b[0m, in \u001b[0;36mSentenceTransformer._load_sbert_model\u001b[1;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[0m\n\u001b[0;32m   2248\u001b[0m         module \u001b[38;5;241m=\u001b[39m module_class\u001b[38;5;241m.\u001b[39mload(local_path)\n\u001b[0;32m   2250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2251\u001b[0m     \u001b[38;5;66;03m# Newer modules that support the new loading method are loaded with the new style\u001b[39;00m\n\u001b[0;32m   2252\u001b[0m     \u001b[38;5;66;03m# i.e. with many keyword arguments that can optionally be used by the modules\u001b[39;00m\n\u001b[1;32m-> 2253\u001b[0m     module \u001b[38;5;241m=\u001b[39m module_class\u001b[38;5;241m.\u001b[39mload(\n\u001b[0;32m   2254\u001b[0m         model_name_or_path,\n\u001b[0;32m   2255\u001b[0m         \u001b[38;5;66;03m# Loading-specific keyword arguments\u001b[39;00m\n\u001b[0;32m   2256\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39mmodule_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   2257\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   2258\u001b[0m         cache_folder\u001b[38;5;241m=\u001b[39mcache_folder,\n\u001b[0;32m   2259\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   2260\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m   2261\u001b[0m         \u001b[38;5;66;03m# Module-specific keyword arguments\u001b[39;00m\n\u001b[0;32m   2262\u001b[0m         trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[0;32m   2263\u001b[0m         model_kwargs\u001b[38;5;241m=\u001b[39mmodel_kwargs,\n\u001b[0;32m   2264\u001b[0m         tokenizer_kwargs\u001b[38;5;241m=\u001b[39mtokenizer_kwargs,\n\u001b[0;32m   2265\u001b[0m         config_kwargs\u001b[38;5;241m=\u001b[39mconfig_kwargs,\n\u001b[0;32m   2266\u001b[0m         backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend,\n\u001b[0;32m   2267\u001b[0m     )\n\u001b[0;32m   2269\u001b[0m modules[module_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m module\n\u001b[0;32m   2270\u001b[0m module_kwargs[module_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m module_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n",
            "File \u001b[1;32mc:\\Users\\amir\\anaconda4\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:338\u001b[0m, in \u001b[0;36mTransformer.load\u001b[1;34m(cls, model_name_or_path, subfolder, token, cache_folder, revision, local_files_only, trust_remote_code, model_kwargs, tokenizer_kwargs, config_kwargs, backend, **kwargs)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    324\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m    325\u001b[0m     init_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_load_init_kwargs(\n\u001b[0;32m    326\u001b[0m         model_name_or_path\u001b[38;5;241m=\u001b[39mmodel_name_or_path,\n\u001b[0;32m    327\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    336\u001b[0m         backend\u001b[38;5;241m=\u001b[39mbackend,\n\u001b[0;32m    337\u001b[0m     )\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(model_name_or_path\u001b[38;5;241m=\u001b[39mmodel_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minit_kwargs)\n",
            "File \u001b[1;32mc:\\Users\\amir\\anaconda4\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:87\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[1;34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path, backend)\u001b[0m\n\u001b[0;32m     84\u001b[0m     config_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     86\u001b[0m config, is_peft_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_config(model_name_or_path, cache_dir, backend, config_args)\n\u001b[1;32m---> 87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_model(model_name_or_path, config, cache_dir, backend, is_peft_model, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_seq_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_max_length\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tokenizer_args:\n\u001b[0;32m     90\u001b[0m     tokenizer_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_max_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m max_seq_length\n",
            "File \u001b[1;32mc:\\Users\\amir\\anaconda4\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:185\u001b[0m, in \u001b[0;36mTransformer._load_model\u001b[1;34m(self, model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_mt5_model(model_name_or_path, config, cache_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args)\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 185\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model \u001b[38;5;241m=\u001b[39m AutoModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    186\u001b[0m             model_name_or_path, config\u001b[38;5;241m=\u001b[39mconfig, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args\n\u001b[0;32m    187\u001b[0m         )\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monnx\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model \u001b[38;5;241m=\u001b[39m load_onnx_model(\n\u001b[0;32m    190\u001b[0m         model_name_or_path\u001b[38;5;241m=\u001b[39mmodel_name_or_path,\n\u001b[0;32m    191\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    192\u001b[0m         task_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature-extraction\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    193\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args,\n\u001b[0;32m    194\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\amir\\anaconda4\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:543\u001b[0m, in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mauto_map\n\u001b[0;32m    540\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m    541\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m resolve_trust_remote_code(\n\u001b[0;32m    542\u001b[0m     trust_remote_code, pretrained_model_name_or_path, has_local_code, has_remote_code\n\u001b[1;32m--> 543\u001b[0m )\n\u001b[0;32m    545\u001b[0m \u001b[38;5;66;03m# Set the adapter kwargs\u001b[39;00m\n\u001b[0;32m    546\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madapter_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m adapter_kwargs\n",
            "File \u001b[1;32mc:\\Users\\amir\\anaconda4\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:781\u001b[0m, in \u001b[0;36mkeys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mitems\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    776\u001b[0m     mapping_items \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    777\u001b[0m         (\n\u001b[0;32m    778\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_attr_from_module(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_mapping[key]),\n\u001b[0;32m    779\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_attr_from_module(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping[key]),\n\u001b[0;32m    780\u001b[0m         )\n\u001b[1;32m--> 781\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m    782\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_mapping\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m    783\u001b[0m     ]\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping_items \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extra_content\u001b[38;5;241m.\u001b[39mitems())\n",
            "File \u001b[1;32mc:\\Users\\amir\\anaconda4\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:777\u001b[0m, in \u001b[0;36m_load_attr_from_module\u001b[1;34m(self, model_type, attr)\u001b[0m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mitems\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    776\u001b[0m     mapping_items \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 777\u001b[0m         (\n\u001b[0;32m    778\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_attr_from_module(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_mapping[key]),\n\u001b[0;32m    779\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_attr_from_module(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping[key]),\n\u001b[0;32m    780\u001b[0m         )\n\u001b[0;32m    781\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m    782\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_mapping\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m    783\u001b[0m     ]\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping_items \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extra_content\u001b[38;5;241m.\u001b[39mitems())\n",
            "File \u001b[1;32mc:\\Users\\amir\\anaconda4\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:693\u001b[0m, in \u001b[0;36mgetattribute_from_module\u001b[1;34m(module, attr)\u001b[0m\n\u001b[0;32m    691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(getattribute_from_module(module, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m attr)\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(module, attr):\n\u001b[1;32m--> 693\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, attr)\n\u001b[0;32m    694\u001b[0m \u001b[38;5;66;03m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;66;03m# object at the top level.\u001b[39;00m\n\u001b[0;32m    696\u001b[0m transformers_module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\amir\\anaconda4\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1766\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1749\u001b[0m TORCHVISION_IMPORT_ERROR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m requires the Torchvision library but it was not found in your environment. Check out the instructions on the\u001b[39m\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;124minstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\u001b[39m\n\u001b[0;32m   1752\u001b[0m \u001b[38;5;124mPlease note that you may need to restart your runtime after installation.\u001b[39m\n\u001b[0;32m   1753\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   1755\u001b[0m \u001b[38;5;66;03m# docstyle-ignore\u001b[39;00m\n\u001b[0;32m   1756\u001b[0m PYTORCH_IMPORT_ERROR_WITH_TF \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m requires the PyTorch library but it was not found in your environment.\u001b[39m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;124mHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\u001b[39m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;124mwith \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, but are otherwise identically named to our PyTorch classes. This\u001b[39m\n\u001b[0;32m   1760\u001b[0m \u001b[38;5;124mmeans that the TF equivalent of the class you tried to import would be \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\n\u001b[0;32m   1761\u001b[0m \u001b[38;5;124mIf you want to use TensorFlow, please use TF classes instead!\u001b[39m\n\u001b[0;32m   1762\u001b[0m \n\u001b[0;32m   1763\u001b[0m \u001b[38;5;124mIf you really do want to use PyTorch please go to\u001b[39m\n\u001b[0;32m   1764\u001b[0m \u001b[38;5;124mhttps://pytorch.org/get-started/locally/ and follow the instructions that\u001b[39m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;124mmatch your environment.\u001b[39m\n\u001b[1;32m-> 1766\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   1768\u001b[0m \u001b[38;5;66;03m# docstyle-ignore\u001b[39;00m\n\u001b[0;32m   1769\u001b[0m TF_IMPORT_ERROR_WITH_PYTORCH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   1770\u001b[0m \u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m requires the TensorFlow library but it was not found in your environment.\u001b[39m\n\u001b[0;32m   1771\u001b[0m \u001b[38;5;124mHowever, we were able to find a PyTorch installation. PyTorch classes do not begin\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1776\u001b[0m \u001b[38;5;124minstallation page https://www.tensorflow.org/install that match your environment.\u001b[39m\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\amir\\anaconda4\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1780\u001b[0m, in \u001b[0;36m_get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1769\u001b[0m TF_IMPORT_ERROR_WITH_PYTORCH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   1770\u001b[0m \u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m requires the TensorFlow library but it was not found in your environment.\u001b[39m\n\u001b[0;32m   1771\u001b[0m \u001b[38;5;124mHowever, we were able to find a PyTorch installation. PyTorch classes do not begin\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1776\u001b[0m \u001b[38;5;124minstallation page https://www.tensorflow.org/install that match your environment.\u001b[39m\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# docstyle-ignore\u001b[39;00m\n\u001b[1;32m-> 1780\u001b[0m BS4_IMPORT_ERROR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m requires the Beautiful Soup library but it was not found in your environment. You can install it with pip:\u001b[39m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;124m`pip install beautifulsoup4`. Please note that you may need to restart your runtime after installation.\u001b[39m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# docstyle-ignore\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m SKLEARN_IMPORT_ERROR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m requires the scikit-learn library but it was not found in your environment. You can install it with:\u001b[39m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;124m```\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1796\u001b[0m \u001b[38;5;124mPlease note that you may need to restart your runtime after installation.\u001b[39m\n\u001b[0;32m   1797\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.models.chameleon.configuration_chameleon because of the following error (look up to see its traceback):\nNo module named 'transformers.models.chameleon.configuration_chameleon'"
          ]
        }
      ],
      "source": [
        "# =====================\n",
        "# 2. Create embeddings + ChromaDB\n",
        "# =====================\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "vectorstore = Chroma.from_documents(chunks, embeddings, persist_directory=\"./chroma_db\")\n",
        "print(\"✅ Data stored in Chroma\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "dd4c222eb49c43d780164a656a627369",
            "a41cd1a72510462596984ce7f978ccef",
            "092004d199d14346921a046b348d6281",
            "21d2d560b3574169b4615ea03571aa1d",
            "88e58c14bc0b4717b1a2ecead7ac1bf3",
            "8fa4664dd8e6406ca459b4fdf98db463",
            "d75bad41af784317820f09a5b5860f96",
            "4344f612ea4741b5a836f956178d6a55",
            "0bced0e3241e4da9b8cf7d2106ce85fb",
            "0f5e4f9119ac4d69b0ce9a7d46dc3a73",
            "996c49388cca4534ad50b165a8e8fb81",
            "4f880b2a04434c96b2b15765876bd4c4",
            "e6865d6256164e00a4683cfa7284e336",
            "74256c246fac494cad4bc4cb908d7d3e",
            "17d0cf212fdf428dae1c71134da3cf48",
            "191ee96a8e5a4641a3a3492d8cd99b35",
            "0b6b0be2e9b84d389ff39a6487e97a24",
            "09001e034c974b6e862113978ca52708",
            "26e6626b85574cc09900d847b8922f3c",
            "e8239d17cd6c4311b0e6ec65cbaece26",
            "a9be2e2e8aa645028ed500180c0a4b78",
            "c59055d43e70486499fa1a4b7f789895"
          ]
        },
        "id": "2ikoXVHCp5Mp",
        "outputId": "597763dd-d81d-4dbd-d778-a1a369116a3c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd4c222eb49c43d780164a656a627369",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/930 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f880b2a04434c96b2b15765876bd4c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/24.2G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# =====================\n",
        "# 3. Setup LLM (GPT-J from HuggingFace)\n",
        "# =====================\n",
        "llm = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"EleutherAI/gpt-j-6B\",\n",
        "    device=-1,  # -1 = CPU, or 0 = GPU if available\n",
        "    max_new_tokens=200,\n",
        "    do_sample=True,\n",
        "    temperature=0.7\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "2iAE984-t2tn",
        "outputId": "c5a6bbf7-a682-4a8c-8750-5aad21bc1089"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'vectorstore' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2297709940.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Step 1: Get relevant chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mretriever\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_retriever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"k\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_relevant_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vectorstore' is not defined"
          ]
        }
      ],
      "source": [
        "# =====================\n",
        "# 4. Ask a question\n",
        "# =====================\n",
        "query = \"ما هي خدمات شركة الشفاء الرقمية؟\"\n",
        "\n",
        "# Step 1: Get relevant chunks\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "docs = retriever.get_relevant_documents(query)\n",
        "\n",
        "context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "# Step 2: Build prompt\n",
        "prompt = f\"السؤال: {query}\\n\\nالمعلومات المتاحة:\\n{context}\\n\\nالإجابة:\"\n",
        "\n",
        "# Step 3: Get answer from LLM\n",
        "response = llm(prompt)[0][\"generated_text\"]\n",
        "\n",
        "print(\"\\n--- Final Answer ---\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtxDDQyRt2rW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSJemvIGt2nq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5_QKeEXt2kI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09001e034c974b6e862113978ca52708": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "092004d199d14346921a046b348d6281": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4344f612ea4741b5a836f956178d6a55",
            "max": 930,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0bced0e3241e4da9b8cf7d2106ce85fb",
            "value": 930
          }
        },
        "0b6b0be2e9b84d389ff39a6487e97a24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bced0e3241e4da9b8cf7d2106ce85fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f5e4f9119ac4d69b0ce9a7d46dc3a73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17d0cf212fdf428dae1c71134da3cf48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9be2e2e8aa645028ed500180c0a4b78",
            "placeholder": "​",
            "style": "IPY_MODEL_c59055d43e70486499fa1a4b7f789895",
            "value": " 24.2G/24.2G [12:33&lt;00:00, 124MB/s]"
          }
        },
        "191ee96a8e5a4641a3a3492d8cd99b35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21d2d560b3574169b4615ea03571aa1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f5e4f9119ac4d69b0ce9a7d46dc3a73",
            "placeholder": "​",
            "style": "IPY_MODEL_996c49388cca4534ad50b165a8e8fb81",
            "value": " 930/930 [00:00&lt;00:00, 91.7kB/s]"
          }
        },
        "26e6626b85574cc09900d847b8922f3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4344f612ea4741b5a836f956178d6a55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f880b2a04434c96b2b15765876bd4c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6865d6256164e00a4683cfa7284e336",
              "IPY_MODEL_74256c246fac494cad4bc4cb908d7d3e",
              "IPY_MODEL_17d0cf212fdf428dae1c71134da3cf48"
            ],
            "layout": "IPY_MODEL_191ee96a8e5a4641a3a3492d8cd99b35"
          }
        },
        "74256c246fac494cad4bc4cb908d7d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26e6626b85574cc09900d847b8922f3c",
            "max": 24207819307,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8239d17cd6c4311b0e6ec65cbaece26",
            "value": 24207819307
          }
        },
        "88e58c14bc0b4717b1a2ecead7ac1bf3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fa4664dd8e6406ca459b4fdf98db463": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "996c49388cca4534ad50b165a8e8fb81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a41cd1a72510462596984ce7f978ccef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fa4664dd8e6406ca459b4fdf98db463",
            "placeholder": "​",
            "style": "IPY_MODEL_d75bad41af784317820f09a5b5860f96",
            "value": "config.json: 100%"
          }
        },
        "a9be2e2e8aa645028ed500180c0a4b78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c59055d43e70486499fa1a4b7f789895": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d75bad41af784317820f09a5b5860f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd4c222eb49c43d780164a656a627369": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a41cd1a72510462596984ce7f978ccef",
              "IPY_MODEL_092004d199d14346921a046b348d6281",
              "IPY_MODEL_21d2d560b3574169b4615ea03571aa1d"
            ],
            "layout": "IPY_MODEL_88e58c14bc0b4717b1a2ecead7ac1bf3"
          }
        },
        "e6865d6256164e00a4683cfa7284e336": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b6b0be2e9b84d389ff39a6487e97a24",
            "placeholder": "​",
            "style": "IPY_MODEL_09001e034c974b6e862113978ca52708",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "e8239d17cd6c4311b0e6ec65cbaece26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
